{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00ec7ce",
   "metadata": {},
   "source": [
    "## Proje Dokümantasyonu\n",
    "\n",
    "### 1. Giriş ve Veri Seti Açıklaması\n",
    "- Bu bölümde, projenin amacı, kapsamı ve kullanılan veri setleri hakkında genel bilgiler sunulur.\n",
    "\n",
    "### 2. Veri Hazırlığı\n",
    "- Veri setinin okunması, temizlenmesi ve analize uygun hale getirilmesi süreçleri detaylandırılır.\n",
    "\n",
    "### 3. Çözümle İlgili Genel Yaklaşım\n",
    "- Projede izlenen strateji ve çözümün genel hatları açıklanır.\n",
    "\n",
    "### 4. Churn Merchants\n",
    "#### Churn Merchants Tespiti ve Tahminlenmesi:\n",
    "- Churn olan müşterilerin tespit edilmesi ve bu müşterilere ilişkin tahminlerin yapılma yöntemleri anlatılır.\n",
    "\n",
    "### 5. Full Merchants\n",
    "#### Full Merchants Tespiti ve Modellenmesi:\n",
    "- Projede \"Full Merchant\" olarak tanımlanan müşteri grubunun nasıl tespit edildiği ve bu grup üzerinde yapılan modelleme işlemleri detaylandırılır.\n",
    "\n",
    "### 6. Active Merchants\n",
    "#### Active Merchants Tespiti ve Kural Tabanlı Sistemin Uygulanması:\n",
    "- Aktif müşterilerin nasıl belirlendiği ve bu müşterilere özel uygulanan kural tabanlı sistem anlatılır.\n",
    "\n",
    "### 7. Sonuçların Birleştirilmesi ve Kaydedilmesi\n",
    "- Farklı müşteri grupları için elde edilen sonuçların nasıl birleştirildiği ve sonuçların nasıl kaydedildiği üzerine bilgiler verilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abcae6",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c358d69",
   "metadata": {},
   "source": [
    "## 1. Giriş ve Veri Seti Açıklaması\n",
    "\n",
    "Bu notebook, iyzico ve Coderspace işbirliğiyle düzenlenen iyzico Datathon yarışmasındaki **Public LB'da 3. ve Private LB'da 4.** olarak yarışmayı tamamladığım çalışmadır. iyzico, 2013 yılında kurularak finansal hizmetleri daha erişilebilir hale getirmeyi amaçlamıştır. Yapay zeka tabanlı sanal POS ve ödeme teknolojileri ile 100 binden fazla üye iş yeriyle çalışmış ve alternatif ödeme yöntemleri sunarak alışverişi kolaylaştırmıştır.\n",
    "\n",
    "Bu çalışmada, iyzico'nun sağladığı veri setini kullanarak 2023 yılının son çeyreği için iş yerlerinin işlem sayılarını (net_payment_count) tahmin edeceğim. Eğitim veri seti (train.csv), 2020'nin başından 2023'ün Eylül ayına kadar aylık işlem sayılarını içermektedir.\n",
    "\n",
    "Veri seti şu bilgileri içerir:\n",
    "- **merchant_id**: Maskelenmiş iş yeri ID'si.\n",
    "- **month_id**: İşlemin yapıldığı ay, YYYYMM formatında.\n",
    "- **net_payment_count**: İş yerinin ay içindeki net işlem sayısı.\n",
    "\n",
    "Verisetinde toplamda 8 kolon bulunmaktadır. Veri analizi sürecinde bu bilgileri kullanarak çalışmayla alakalı bir strateji geliştirdim. Veri analizim sonrası modelleme ve tahmin sürecinde sadece 3 kolonu kullandım. Kurallar gereği veri seti, çalışmaların çıktıları ve veri analizi sürecini public olarak paylaşamamaktayım. Yukarıdaki data card, yarışma kapsamında geliştirdiğim modelin anlaşılabilirliğini artırmak için veri setindeki kolonların açıklamalarını içermekte olup, yalnızca eğitimsel ve bilgi paylaşım amaçlıdır ve veri setindeki kolonların sadece bir kısmıdır.\n",
    "\n",
    "Bu çalışma, yarışma içerisinde; **Public Score'u 28.87614 (LB: 3/328 Teams)** , **Private Score'u 30.74141 (LB: 4/328 Teams)** olan tahminin elde edildiği çalışmadır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b0bc9",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eafdc6",
   "metadata": {},
   "source": [
    "## 2. Veri Hazırlığı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf55a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphanelerin import edilmesi\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import itertools\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from numpy.linalg import LinAlgError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83309036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setinin yüklenmesi\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setinin pivot tablo olarak hazırlanması\n",
    "\n",
    "def prepare_pivot_table(data):\n",
    "    data['month_id'] = data['month_id'].astype(str)\n",
    "    pivot_table = data.pivot_table(index='merchant_id', \n",
    "                                   columns='month_id', \n",
    "                                   values='net_payment_count',\n",
    "                                   aggfunc='sum').reset_index()\n",
    "    return pivot_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot tablosunun sütun başlıklarını düzeltilmesi\n",
    "\n",
    "def flatten_pivot_table_columns(pivot_table):\n",
    "    pivot_table = pivot_table.reset_index()\n",
    "\n",
    "    new_columns = []\n",
    "    for col in pivot_table.columns:\n",
    "        if isinstance(col, tuple):\n",
    "            new_columns.append('_'.join(str(lev) for lev in col if str(lev) != ''))\n",
    "        else:\n",
    "            new_columns.append(col)\n",
    "    pivot_table.columns = new_columns\n",
    "\n",
    "    return pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cf23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = 'train.csv'\n",
    "data = load_data(data_file_name)\n",
    "pivot_table = prepare_pivot_table(data)\n",
    "pivot_table = flatten_pivot_table_columns(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb737a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729d59e",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae2f1c",
   "metadata": {},
   "source": [
    "## 3. Çözümle İlgili Genel Yaklaşım\n",
    "\n",
    "Yaptığım veri analizi sonucunda, verisetimi **3 parça** halinde incelemeye karar verdim.\n",
    "\n",
    "1. **parça churn müşterilerimiz,**\n",
    "2. **parça kesintisiz alım yapan ve en yenisi son 24 aydır müşterimiz olan full müşterilerimiz,**\n",
    "3. **parça churn olmayan fakat kesintisiz alım yapmayan active müşterilerimiz.**\n",
    "\n",
    "Bu 3 ayrı parçaya birbirinden farklı yaklaşımlarla tahmin süreçleri kurdum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fa4b8",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86aa672",
   "metadata": {},
   "source": [
    "## 4. Churn Merchants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220b509",
   "metadata": {},
   "source": [
    "### Churn Olan Merchant_id'lerin Tespiti:\n",
    "\n",
    "- Bu bölümde, **son üç ay** içerisinde herhangi bir aktivitesi olmayan ve bu durumuyla potansiyel olarak churn olmuş merchant'ların tespiti yapılmaktadır. \n",
    "- Bu işlem için son üç ayı temsil eden sütun isimleri (**202307, 202308, 202309**) kullanılmakta ve bu dönemlerde NaN değerlere sahip merchant_idler belirlenmektedir. Bu merchant_idler bir liste halinde (churn_list) saklanmaktadır. \n",
    "- Tespit edilen bu merchant_idlere ait kayıtlar daha sonra ele alınarak, gelecek üç ay (**202310, 202311, 202312**) için tahminler **0** olarak belirlenmektedir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0feb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_churn_merchants(pivot_table):\n",
    "    \n",
    "    # Geçmiş 3 ay için churn merchant'ların tespit edilmesi\n",
    "    last_three_months_columns = ['202307', '202308', '202309']\n",
    "    churn_list = pivot_table[pivot_table[last_three_months_columns].isna().all(axis=1)]['merchant_id']\n",
    "    churn_merchants = pivot_table[pivot_table['merchant_id'].isin(churn_list)]\n",
    "    \n",
    "    # Gelecek 3 ay için tahmin sütunlarını oluşturma ve 0 olarak atama\n",
    "    prediction_months = [\"202310\", \"202311\", \"202312\"]\n",
    "    for month in prediction_months:\n",
    "        churn_merchants.loc[:, month] = 0\n",
    "    \n",
    "    return churn_merchants\n",
    "\n",
    "\n",
    "churn_merchants = detect_churn_merchants(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c0b5a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d88ba",
   "metadata": {},
   "source": [
    "## 5. Full Merchants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc1ad6",
   "metadata": {},
   "source": [
    "### Model Genel Bakış\n",
    "\n",
    "Modelin uygulama süreci aşağıdaki adımlar izlenerek gerçekleştirilmiştir:\n",
    "\n",
    "1. **Veri Hazırlığı:** Churn olmuş merchant'lar veri setinden çıkarılmıştır. Daha sonra, kalan veri üzerinde filtreleme işlemi yapılmıştır. Filtreleme, son 45 aydır müşteri olan ve hiç NaN değeri bulunmayan merchant'lar ile başlayıp, süreç son 24 aydır müşteri olan ve hiç NaN değeri bulunmayan merchant'lar ile bitirilmiştir. Bu süreçte model uygulanan tüm merchant'lar, 'full merchant' olarak değerlendirilmiştir.\n",
    "\n",
    "2. **Model İçeriği:** Merchant'lara ARIMA ve SARIMAX modelleri uygulanmıştır. Bu modeller için `p, d, q` ve `P, D, Q` parametreleri için belirlenen aralıklar `range(0,2)`, mevsimsel etkiler için ise `range(11,13)` olarak ayarlanmıştır. Bu belirlenen aralıklar üzerinden, grid-search yöntemi ile hiperparametre optimizasyonu yapılmıştır. \n",
    "\n",
    "3. **Hiperparametre Optimizasyonu ve Model Seçimi:** Parametreler ve tahminler için DataFrame'ler oluşturulmuştur. ARIMA ve SARIMAX modelleri için hiperparametre optimizasyonu gerçekleştiren bir fonksiyon yazılmıştır. Bu fonksiyon, her merchant için en düşük ortalama MAE'yi sağlayan hiperparametreleri seçer. Modellerin performansı karşılaştırılarak, en düşük MAE'yi veren model ve bu modeldeki hiperparametreler belirlenir. Bu model, final model olarak kabul edilir ve merchant'ın tahminleri bu model üzerinden alınır.\n",
    "\n",
    "4. **Cross-Validation (Çapraz Doğrulama):** Toplamda 6 fold aşağıdaki gibi tanımlanmıştır:\n",
    "\n",
    "   - `(data[:-3], data[-3:])`,   # 1. fold (202307-202309)\n",
    "   - `(data[:-4], data[-4:-1])`, # 2. fold (202306-202308)\n",
    "   - `(data[:-5], data[-5:-2])`, # 3. fold (202305-202307)\n",
    "   - `(data[:-6], data[-6:-3])`, # 4. fold (202304-202306)\n",
    "   - `(data[:-7], data[-7:-4])`, # 5. fold (202303-202305)\n",
    "   - `(data[:-8], data[-8:-5])`, # 6. fold (202302-202304)\n",
    "\n",
    "Model, üç aşamalı bir süreçten geçirilmiştir:\n",
    "\n",
    "1. İlk aşamada, ilk fold için hiperparametre optimizasyonu yapılarak final model ile tahmin alınır.\n",
    "2. İkinci aşamada, ilk 3 fold için ortalama MAE'ye göre hiperparametre optimizasyonu yapılarak final model ile tahmin alınır.\n",
    "3. Üçüncü aşamada, tüm foldlar için, yani 6 fold için ortalama MAE'ye göre hiperparametre optimizasyonu yapılarak final model ile tahmin alınır.\n",
    "\n",
    "Bir merchant, süreç boyunca ilk olarak ARIMA, sonra SARIMAX ve son olarak yine SARIMAX modelini final model olarak seçebilir. Son tahminler, bu üç süreçten elde edilen tahminlerin ortalaması alınarak ve 202310, 202311 ve 202312 ayları için final tahminler elde edilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verisetin'den tahmini tamamlanan churn merchantların çıkarılması\n",
    "\n",
    "active_merchants = pivot_table[~pivot_table['merchant_id'].isin(churn_list)] \n",
    "active_merchants = active_merchants.set_index('merchant_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8219c32",
   "metadata": {},
   "source": [
    "### Modelin Uygulanması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merchants = active_merchants.copy()\n",
    "\n",
    "# SARIMA ve ARIMA hiperparametreleri tanımlanır.\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "# Parametrelerin ve tahminlerin saklanması için DataFrame'ler oluşturulur.\n",
    "params = pd.DataFrame(columns=['merchant_id', 'process', 'model_type', 'best_order', 'best_seasonal_order', 'best_mae'])\n",
    "forecast_months = [\"202310\", \"202311\", \"202312\"]\n",
    "\n",
    "# Model optimizasyon fonksiyonu tanımlanır.\n",
    "def model_optimizer_mae(train_test_sets, orders, seasonal_orders=None, is_sarimax=False):\n",
    "    best_mae, best_params, best_seasonal_params = float(\"inf\"), None, None\n",
    "    for order in orders:\n",
    "        if is_sarimax:\n",
    "            for seasonal_order in seasonal_orders:\n",
    "                total_mae = 0\n",
    "                try:\n",
    "                    for train, test in train_test_sets:\n",
    "                        model = SARIMAX(train, order=order, seasonal_order=seasonal_order)\n",
    "                        model_fit = model.fit(disp=0)\n",
    "                        y_pred = model_fit.get_forecast(steps=len(test)).predicted_mean\n",
    "                        total_mae += mean_absolute_error(test, y_pred)\n",
    "                    avg_mae = total_mae / len(train_test_sets)\n",
    "                    if avg_mae < best_mae:\n",
    "                        best_mae, best_params, best_seasonal_params = avg_mae, order, seasonal_order\n",
    "                except (LinAlgError, ValueError):\n",
    "                    continue\n",
    "        else:  # ARIMA\n",
    "            try:\n",
    "                total_mae = 0\n",
    "                for train, test in train_test_sets:\n",
    "                    model = ARIMA(train, order=order)\n",
    "                    model_fit = model.fit()\n",
    "                    y_pred = model_fit.forecast(steps=len(test))\n",
    "                    total_mae += mean_absolute_error(test, y_pred)\n",
    "                avg_mae = total_mae / len(train_test_sets)\n",
    "                if avg_mae < best_mae:\n",
    "                    best_mae, best_params = avg_mae, order\n",
    "            except (LinAlgError, ValueError):\n",
    "                continue\n",
    "                \n",
    "    return best_mae, best_params, best_seasonal_params\n",
    "\n",
    "# Süreçlerin tanımlanması ve iterasyonları gerçekleştirilir.\n",
    "process_names = {1: \"1_fold\", 3: \"3_fold\", 6: \"6_fold\"}\n",
    "\n",
    "# Final tahminlerin saklanması için bir sözlük oluşturulur.\n",
    "final_predictions = {}\n",
    "\n",
    "# Filtreleme ve tahmin süreçleri\n",
    "for months_back in range(45, 23, -1):\n",
    "    \n",
    "    active_filter = active_merchants.iloc[:, -months_back:].dropna(thresh=months_back)\n",
    "    filtered_merchants = active_filter.index.tolist()\n",
    "\n",
    "    for merchant_id in tqdm(filtered_merchants):\n",
    "        data = active_filter.loc[merchant_id].values\n",
    "        temp_predictions = {month: [] for month in forecast_months}\n",
    "\n",
    "        for process, process_name in process_names.items():\n",
    "            \n",
    "            # Fold'lar tanımlanır.\n",
    "            train_test_sets = [(data[:-n], data[-n:]) for n in range(3, 3 + process)]\n",
    "            \n",
    "            # SARIMAX ve ARIMA için optimizasyonlar gerçekleştirilir.\n",
    "            sarimax_mae, sarimax_best_order, sarimax_best_seasonal_order = model_optimizer_mae(\n",
    "                train_test_sets, pdq, seasonal_pdq, is_sarimax=True\n",
    "            )\n",
    "            arima_mae, arima_best_order, _ = model_optimizer_mae(\n",
    "                train_test_sets, pdq, is_sarimax=False\n",
    "            )\n",
    "\n",
    "            \n",
    "            # En iyi modelle tahmin yapılır.\n",
    "            if sarimax_mae < arima_mae:\n",
    "                final_model = SARIMAX(data, order=sarimax_best_order, seasonal_order=sarimax_best_seasonal_order)\n",
    "                final_model_fit = final_model.fit(disp=0)\n",
    "                forecast = final_model_fit.get_forecast(steps=3).predicted_mean\n",
    "                model_type = 'SARIMAX'\n",
    "                best_order, best_seasonal_order, overall_best_mae = sarimax_best_order, sarimax_best_seasonal_order, sarimax_mae\n",
    "            else:\n",
    "                final_model = ARIMA(data, order=arima_best_order)\n",
    "                final_model_fit = final_model.fit()\n",
    "                forecast = final_model_fit.forecast(steps=3)\n",
    "                model_type = 'ARIMA'\n",
    "                best_order, best_seasonal_order, overall_best_mae = arima_best_order, None, arima_mae\n",
    "            \n",
    "            # Her bir süreç için parametreler ve tahminler saklanır.\n",
    "            params_row = {\n",
    "                'merchant_id': merchant_id,\n",
    "                'process': process_name,\n",
    "                'model_type': model_type,\n",
    "                'best_order': str(best_order),\n",
    "                'best_seasonal_order': str(best_seasonal_order) if best_seasonal_order is not None else None,\n",
    "                'best_mae': overall_best_mae\n",
    "            }\n",
    "            params = pd.concat([params, pd.DataFrame([params_row])], ignore_index=True)\n",
    "            \n",
    "            for i, month in enumerate(forecast_months):\n",
    "                temp_predictions[month].append(forecast[i])\n",
    "\n",
    "        # Her bir ay için tahminlerin ortalamasını al ve final_predictions sözlüğünde sakla\n",
    "        final_predictions[merchant_id] = {month: np.mean(temp_predictions[month]) for month in forecast_months}\n",
    "\n",
    "        # final_predictions sözlüğündeki tahminleri kullanarak full_merchants DataFrame'ini güncelle\n",
    "        for merchant_id, predictions in final_predictions.items():\n",
    "            for month, prediction in predictions.items():\n",
    "                full_merchants.loc[merchant_id, month] = prediction\n",
    "    \n",
    "    # Filtrelenen merchant_id'leri çıkar\n",
    "    active_merchants = active_merchants[~(active_merchants.index.isin(filtered_merchants))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18efd7f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d63af8",
   "metadata": {},
   "source": [
    "## 6. Active Merchants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8c67c",
   "metadata": {},
   "source": [
    "### Kural Tabanlı Sistemin Uygulanması: Full Merchants\n",
    "\n",
    "Tespit edilen aktif merchant'lara uygulanacak kural tabanlı sistemin aşamaları şu şekildedir:\n",
    "\n",
    "#### Kural Tabanlı Sisteme Genel Bakış\n",
    "\n",
    "1. **Veri Seti Hazırlığı:**\n",
    "   - `active_merchants`: İlk etapta Churn olmayan merchant_id'lerini içeren bir DataFrame.\n",
    "   - `full_merchants`: Model uygulanan merchant_id'lerini içeren bir DataFrame.\n",
    "   - Güncellenmiş `active_merchants`: Model uygulanan merchant_id'ler DataFrame'den çıkartılarak uygulama yapıldığı için DataFrame'de kalan kişiler bizim için kural tabanlı sistemin uygulanacağı, güncellenmiş merchant_id'lerini barındıran bir DataFrame.\n",
    "\n",
    "#### Kural Tabanlı Sistemin Uygulanması\n",
    "\n",
    "1. **İşlem Hacmindeki Yüzdesel Değişim:**\n",
    "   - 202307'den 202308'e ve 202308'den 202309'a geçişteki işlem hacmindeki yüzdesel değişim hesaplanır.\n",
    "\n",
    "2. **Ortalama Değişimin Hesaplanması ve Limitler:**\n",
    "   - Hesaplanan yüzdesel değişimlerin ortalaması alınır. Ancak, dengesizliği önlemek için -%8 ve %8 olarak belirlenen alt ve üst limitler uygulanır.\n",
    "\n",
    "3. **Ortalama Değişime Göre Tahminler:**\n",
    "   - Merchant'ın ortalama değişimi belirlenen aralıklar içindeyse, 202309 ayındaki işlem hacmi bu ortalama değişim oranıyla güncellenir. Bu güncellenmiş işlem hacmi, 202310, 202311 ve 202312 aylarının tahminleri için kullanılır.\n",
    "\n",
    "4. **Limit Aşımı Durumunda Uygulanacak İşlemler:**\n",
    "    - Eğer alt limit aşılmışsa, yani ortalama değişim -%8'den küçükse, bu durumda 202309 ayındaki işlem hacmine alt limit kadar değişim uygulanır. Yani 202309 ayındaki işlem hacmi 0.92 ile çarpılır ve elde edilen işlem hacmi, 202310, 202311 ve 202312 aylarının tahminlerini oluşturmak için kullanılır.\n",
    "   - Eğer üst limit aşılmışsa, yani ortalama değişim %8'den büyükse, bu durumda 202309 ayındaki işlem hacmine üst limit kadar değişim uygulanır. Yani 202309 ayındaki işlem hacmi 1.08 ile çarpılır ve elde edilen işlem hacmi, 202310, 202311 ve 202312 aylarının tahminlerini oluşturmak için kullanılır.\n",
    "\n",
    "Bu yöntemle, işlem hacmindeki değişimlerin ortalaması alınarak, alt ve üst sınırlar belirlenir ve bu sınırlar içinde kalan merchant’lara ortalama değişim uygulanarak tahminler oluşturulur. Ancak, alt veya üst sınırları aşan merchant’lar için bu sınırlara uygun şekilde işlem hacmi düzeltilir ve tahminler bu düzeltilmiş veriler üzerinden yapılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f203b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forecasts(active_merchants):\n",
    "   \n",
    "    # İşlem hacmindeki yüzdesel değişim hesaplanır\n",
    "    percent_change_1 = (active_merchants['202308'] - active_merchants['202307']) / active_merchants['202307'] * 100\n",
    "    percent_change_2 = (active_merchants['202309'] - active_merchants['202308']) / active_merchants['202308'] * 100\n",
    "\n",
    "    # Ortalama yüzdesel değişim hesaplanır\n",
    "    average_percent_change = (percent_change_1.mean() + percent_change_2.mean()) / 2\n",
    "\n",
    "    # Alt ve üst limitler belirlenir\n",
    "    lower_limit = -8\n",
    "    upper_limit = 8\n",
    "\n",
    "    # İşlem hacmi tahminlerinin hesaplanması\n",
    "    if lower_limit <= average_percent_change <= upper_limit:\n",
    "        forecast_multiplier = 1 + average_percent_change / 100\n",
    "    else:\n",
    "        if average_percent_change < lower_limit:\n",
    "            forecast_multiplier = 1 + lower_limit / 100\n",
    "        else:\n",
    "            forecast_multiplier = 1 + upper_limit / 100\n",
    "\n",
    "    # Tahminler için kullanılmak üzere işlem hacmi 202310, 202311 ve 202312 aylarına taşınır\n",
    "    active_merchants['202310'] = active_merchants['202309'] * forecast_multiplier\n",
    "    active_merchants['202311'] = active_merchants['202309'] * forecast_multiplier\n",
    "    active_merchants['202312'] = active_merchants['202309'] * forecast_multiplier\n",
    "\n",
    "    return active_merchants\n",
    "\n",
    "active_merchants = calculate_forecasts(active_merchants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdca3f1",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc46ebf",
   "metadata": {},
   "source": [
    "## 7. Sonuçların Birleştirilmesi ve Kaydedilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a80ce",
   "metadata": {},
   "source": [
    "- **CHURN MERCHANTS**'ların prediction'ları **0,0,0** atanmaktadır.\n",
    "- **FULL MERCHANTS**'ların prediction'ları **modelden** elde edilmektedir. \n",
    "- **ACTIVE MERCHANTS**'ların prediction'ları **kural tabanlı sistem** ile elde edilmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHURN, FULL ve ACTIVE MERCHANTS'ların prediction'larını birleştirme\n",
    "merged_predictions = pd.concat([churn_merchants, full_merchants, active_merchants], axis=0)\n",
    "merged_predictions.reset_index(drop=True, inplace=True)          \n",
    " \n",
    "merged_predictions.to_csv(\"merged_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
